#!/usr/bin/env python3
"""
Debug ìŠ¤í¬ë¦½íŠ¸ - vLLMê³¼ í¬ë¡¤ë§ ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ë…ë¦½ì ì¸ í…ŒìŠ¤íŠ¸
"""

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

def test_vllm_connection():
    """vLLM ì„œë²„ ì—°ê²° í…ŒìŠ¤íŠ¸"""
    print("ğŸ”§ vLLM ì„œë²„ ì—°ê²° í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    try:
        from modules.llm_handler import check_vllm_server, test_vllm_simple
        
        # ì„œë²„ ìƒíƒœ í™•ì¸
        status, message = check_vllm_server()
        print(f"ì„œë²„ ìƒíƒœ: {'âœ…' if status else 'âŒ'} {message}")
        
        if status:
            # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸
            test_status, test_message = test_vllm_simple()
            print(f"í…ŒìŠ¤íŠ¸ ê²°ê³¼: {'âœ…' if test_status else 'âŒ'} {test_message}")
        
        return status
    except Exception as e:
        print(f"âŒ vLLM í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def test_crawler():
    """í¬ë¡¤ë§ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ•·ï¸ í¬ë¡¤ë§ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    try:
        from modules.crawler import crawl_info
        
        # í…ŒìŠ¤íŠ¸ ì¢…ëª©ìœ¼ë¡œ í¬ë¡¤ë§
        ticker = "AAPL"
        date = "2022-01-01"
        
        print(f"ğŸ“ˆ {ticker} í¬ë¡¤ë§ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
        articles, links, debug = crawl_info(ticker, date)
        
        print(f"\nğŸ“Š ê²°ê³¼:")
        print(f"   ìˆ˜ì§‘ëœ ê¸°ì‚¬: {len(articles)}ê°œ")
        print(f"   ì°¸ê³  ë§í¬: {len(links)}ê°œ")
        print(f"   ë””ë²„ê·¸ í•­ëª©: {len(debug)}ê°œ")
        
        print(f"\nğŸ“° ê¸°ì‚¬ ìƒ˜í”Œ (ì²˜ìŒ 3ê°œ):")
        for i, article in enumerate(articles[:3], 1):
            print(f"   {i}. {article[:100]}...")
        
        print(f"\nğŸ” ë””ë²„ê·¸ ì •ë³´ (ë§ˆì§€ë§‰ 5ê°œ):")
        for debug_item in debug[-5:]:
            print(f"   {debug_item}")
        
        return len(articles) > 0
    except Exception as e:
        print(f"âŒ í¬ë¡¤ë§ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        print(traceback.format_exc())
        return False

def test_full_integration():
    """ì „ì²´ í†µí•© í…ŒìŠ¤íŠ¸"""
    print("\nğŸ§© ì „ì²´ í†µí•© í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    try:
        from modules.crawler import crawl_info
        from modules.llm_handler import run_llm
        
        ticker = "AAPL"
        date = "2022-01-01"
        return_pct = 25.5
        language = "í•œêµ­ì–´"
        
        print(f"ğŸš€ {ticker} ì „ì²´ í”„ë¡œì„¸ìŠ¤ í…ŒìŠ¤íŠ¸...")
        
        # 1. í¬ë¡¤ë§
        print("1ï¸âƒ£ í¬ë¡¤ë§ ë‹¨ê³„...")
        articles, links, debug = crawl_info(ticker, date)
        print(f"   âœ… í¬ë¡¤ë§ ì™„ë£Œ: {len(articles)}ê°œ ê¸°ì‚¬")
        
        # 2. LLM ë¶„ì„
        print("2ï¸âƒ£ LLM ë¶„ì„ ë‹¨ê³„...")
        recommendation, prompt = run_llm(ticker, date, return_pct, articles, language)
        print(f"   âœ… LLM ë¶„ì„ ì™„ë£Œ")
        print(f"   ğŸ“ ì¶”ì²œ ë‚´ìš©: {recommendation[:100]}...")
        
        return True
    except Exception as e:
        print(f"âŒ í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        print(traceback.format_exc())
        return False

def main():
    """ë©”ì¸ ë””ë²„ê¹… í•¨ìˆ˜"""
    print("ğŸ” AI í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì„ê¸° - ë””ë²„ê¹… ìŠ¤í¬ë¦½íŠ¸")
    print("=" * 60)
    
    # 1. vLLM ì„œë²„ í…ŒìŠ¤íŠ¸
    vllm_ok = test_vllm_connection()
    
    # 2. í¬ë¡¤ë§ í…ŒìŠ¤íŠ¸
    crawler_ok = test_crawler()
    
    # 3. ì „ì²´ í†µí•© í…ŒìŠ¤íŠ¸ (vLLMì´ ì‘ë™í•  ë•Œë§Œ)
    if vllm_ok and crawler_ok:
        integration_ok = test_full_integration()
    else:
        integration_ok = False
        print("\nâš ï¸ vLLM ë˜ëŠ” í¬ë¡¤ë§ ë¬¸ì œë¡œ í†µí•© í…ŒìŠ¤íŠ¸ ê±´ë„ˆëœ€")
    
    # ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 60)
    print("ğŸ¯ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½:")
    print(f"   vLLM ì„œë²„: {'âœ… ì •ìƒ' if vllm_ok else 'âŒ ë¬¸ì œ'}")
    print(f"   í¬ë¡¤ë§: {'âœ… ì •ìƒ' if crawler_ok else 'âŒ ë¬¸ì œ'}")
    print(f"   ì „ì²´ í†µí•©: {'âœ… ì •ìƒ' if integration_ok else 'âŒ ë¬¸ì œ'}")
    
    if not vllm_ok:
        print("\nğŸ’¡ vLLM ì„œë²„ ì‹œì‘ ë°©ë²•:")
        print("   python -m vllm.entrypoints.openai.api_server --model TinyLlama/TinyLlama-1.1B-Chat-v1.0 --port 8000")
    
    if not crawler_ok:
        print("\nğŸ’¡ í¬ë¡¤ë§ ë¬¸ì œ í•´ê²°:")
        print("   pip install feedparser")
        print("   ì¸í„°ë„· ì—°ê²° í™•ì¸")
    
    print("\nğŸ ë””ë²„ê¹… ì™„ë£Œ!")

if __name__ == "__main__":
    main()
