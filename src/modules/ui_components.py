import streamlit as st
import pandas as pd
import yfinance as yf
import plotly.graph_objects as go

from modules.crawler import crawl_info
from modules.llm_handler import run_llm, check_vllm_server, test_vllm_simple
from modules.stock_analyzer import analyze_stock_characteristics, summarize_crawling_process, explain_llm_processing_logic
from config import NUM_REFERENCES, CONFIG_LANGUAGES

# UI Components

def header_ui():
    st.markdown("""
    <div style="background: linear-gradient(90deg, #667eea 0%, #764ba2 100%); padding: 2rem; border-radius: 10px; margin-bottom: 2rem;">
        <h1 style="color: white; text-align: center; margin: 0;">ğŸ“ˆ AI ê¸°ë°˜ í¬íŠ¸í´ë¦¬ì˜¤ ì¶”ì²œ ë¦¬ì„œì¹˜ ë„ìš°ë¯¸</h1>
        <p style="color: white; text-align: center; margin: 0.5rem 0 0 0;">S&P500 ì¢…ëª© ë¶„ì„ ë° AI ê¸°ë°˜ íˆ¬ì ì‚¬ìœ  ë¶„ì„</p>
    </div>
    """, unsafe_allow_html=True)


def sidebar_ui(default_start, default_end):
    st.sidebar.header("ğŸ”§ ë¶„ì„ ì„¤ì •")
    with st.sidebar.expander("ğŸ“… íˆ¬ì ê¸°ê°„ ì„¤ì •", expanded=True):
        start_date = st.date_input("íˆ¬ì ì‹œì‘ì¼:", value=default_start)
        end_date = st.date_input("íˆ¬ì ì¢…ë£Œì¼:", value=default_end)
    with st.sidebar.expander("ğŸ¯ ë¶„ì„ ì¡°ê±´", expanded=True):
        target_return = st.slider("ëª©í‘œ ìˆ˜ìµë¥  (%)", 0.0, 100.0, 10.0, 0.5)
        top_n = st.select_slider("ì¶”ì²œ ì¢…ëª© ìˆ˜", list(range(1,21)), 5)
    # Language selection for LLM output
    language = st.sidebar.selectbox("ì–¸ì–´ ì„ íƒ:", options=CONFIG_LANGUAGES, index=0)
    analyze = st.sidebar.button("ğŸš€ ë¶„ì„ ì‹¤í–‰", type="primary")
    if analyze:
        st.session_state.analyze = True
    return start_date, end_date, target_return, top_n, language


def display_metrics(df):
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("ë¶„ì„ëœ ì¢…ëª© ìˆ˜", len(df), delta="ê°œ")
    with col2:
        st.metric("í‰ê·  ìˆ˜ìµë¥ ", f"{df['Return (%)'].mean():.2f}%")
    with col3:
        st.metric("ìµœê³  ìˆ˜ìµë¥ ", f"{df['Return (%)'].max():.2f}%")
    with col4:
        st.metric("í‰ê·  ë¦¬ìŠ¤í¬", f"{df['Risk (%)'].mean():.2f}%")


def display_table_and_chart(stock_data, start_date, end_date):
    df = pd.DataFrame(stock_data)
    display_df = df.copy()
    display_df['Return (%)'] = display_df['Return (%)'].round(2)
    display_df['Risk (%)'] = display_df['Risk (%)'].round(2)
    col1, col2 = st.columns([1,2])
    with col1:
        st.subheader("ğŸ“Š ì¢…ëª©ë³„ ìˆ˜ìµë¥  & ë¦¬ìŠ¤í¬")
        st.dataframe(display_df, use_container_width=True)
    with col2:
        st.subheader("ğŸ“ˆ í¬íŠ¸í´ë¦¬ì˜¤ ëˆ„ì  ìˆ˜ìµë¥ ")
        chart_period = st.selectbox("ì°¨íŠ¸ ì£¼ê¸° ì„ íƒ", ["ì¼ë´‰","ì£¼ë´‰","ì›”ë´‰"], index=0)
        with st.spinner('ğŸ“ˆ í¬íŠ¸í´ë¦¬ì˜¤ ì„±ê³¼ ê³„ì‚° ì¤‘...'):
            fig = go.Figure()
            for item in stock_data:
                data = yf.Ticker(item['Ticker']).history(start=str(start_date), end=str(end_date))
                if chart_period == "ì£¼ë´‰":
                    data = data.resample('W').agg({'Open':'first','High':'max','Low':'min','Close':'last','Volume':'sum'}).dropna()
                elif chart_period == "ì›”ë´‰":
                    data = data.resample('M').agg({'Open':'first','High':'max','Low':'min','Close':'last','Volume':'sum'}).dropna()
                cumulative = (data['Close'].pct_change().add(1).cumprod() - 1) * 100  # % ë‹¨ìœ„ë¡œ ë³€í™˜
                fig.add_trace(go.Scatter(
                    x=cumulative.index, 
                    y=cumulative.values, 
                    mode='lines', 
                    name=item['Ticker'], 
                    line=dict(width=2),
                    hovertemplate='<b>%{fullData.name}</b><br>' +
                                'Date: %{x}<br>' +
                                'Return: %{y:.2f}%<br>' +
                                '<extra></extra>'
                ))
            fig.update_layout(
                title=f"{chart_period} ëˆ„ì  ìˆ˜ìµë¥  ì¶”ì´", 
                xaxis_title="ë‚ ì§œ", 
                yaxis_title="ëˆ„ì  ìˆ˜ìµë¥  (%)", 
                hovermode='x unified', 
                height=600, 
                showlegend=True, 
                legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1)
            )
            fig.update_xaxes(rangeslider_visible=True)
            st.plotly_chart(fig, use_container_width=True)


def display_risk_info():
    with st.expander("ğŸ“Š ë¦¬ìŠ¤í¬(Risk) ê³„ì‚° ë°©ë²•", expanded=False):
        st.markdown("""
        **ë¦¬ìŠ¤í¬ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ê³„ì‚°ë©ë‹ˆë‹¤:**
        1. **ì¼ë³„ ìˆ˜ìµë¥  ê³„ì‚°**: ì¢…ê°€ ê¸°ì¤€ ìˆ˜ìµë¥  ê³„ì‚°
        2. **í‘œì¤€í¸ì°¨ ê³„ì‚°**: ì¼ë³„ ìˆ˜ìµë¥ ë“¤ì˜ í‘œì¤€í¸ì°¨
        3. **ë°±ë¶„ìœ¨ ë³€í™˜**: í‘œì¤€í¸ì°¨ì— 100 ê³±í•¨
        **í•´ì„:**
        - ë‚®ì€ ë¦¬ìŠ¤í¬ (<2%): ì•ˆì •ì 
        - ì¤‘ê°„ ë¦¬ìŠ¤í¬ (2-5%): ë³´í†µ
        - ë†’ì€ ë¦¬ìŠ¤í¬ (>5%): ë³€ë™ì„± ë†’ìŒ
        """, unsafe_allow_html=True)


def display_ai_analysis(stock_data, start_date, language):
    st.markdown("---")
    st.header("ğŸ¤– AI íˆ¬ì ì‚¬ìœ  ë¶„ì„")
    
    # vLLM ì„œë²„ ìƒíƒœ í™•ì¸
    st.subheader("ğŸ”§ ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸")
    with st.spinner("vLLM ì„œë²„ ì—°ê²° í™•ì¸ ì¤‘..."):
        vllm_status, vllm_message = check_vllm_server()
        
        if vllm_status:
            st.success(f"âœ… {vllm_message}")
            
            # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ìˆ˜í–‰
            test_status, test_message = test_vllm_simple()
            if test_status:
                st.success(f"âœ… vLLM í…ŒìŠ¤íŠ¸: {test_message}")
            else:
                st.warning(f"âš ï¸ vLLM í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {test_message}")
        else:
            st.error(f"âŒ {vllm_message}")
            st.error("vLLM ì„œë²„ë¥¼ ì‹œì‘í•´ì£¼ì„¸ìš”. í„°ë¯¸ë„ì—ì„œ ë‹¤ìŒ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”:")
            st.code("python -m vllm.entrypoints.openai.api_server --model TinyLlama/TinyLlama-1.1B-Chat-v1.0 --port 8000")
            st.stop()
    
    # LLM ì²˜ë¦¬ ë¡œì§ ì„¤ëª…
    with st.expander("ğŸ§  LLM ë°ì´í„° ì²˜ë¦¬ ë¡œì§", expanded=False):
        llm_logic = explain_llm_processing_logic()
        
        st.subheader("ğŸ“¥ ì…ë ¥ ë°ì´í„° ì²˜ë¦¬")
        for step in llm_logic["input_processing"]:
            st.write(f"â€¢ {step}")
        
        st.subheader("ğŸ” ë¶„ì„ ë°©ë²•ë¡ ")
        for method in llm_logic["analysis_methodology"]:
            st.write(f"â€¢ {method}")
        
        st.subheader("ğŸ“¤ ê²°ê³¼ ìƒì„±")
        for output in llm_logic["output_generation"]:
            st.write(f"â€¢ {output}")
        
        st.subheader("âœ… í’ˆì§ˆ ë³´ì¦")
        for qa in llm_logic["quality_assurance"]:
            st.write(f"â€¢ {qa}")
    
    # ë””ë²„ê¹… ì •ë³´ í‘œì‹œ
    debug_container = st.container()
    
    progress = st.progress(0)
    status = st.empty()
    reasons = []
    
    for i, item in enumerate(stock_data):
        ticker = item['Ticker']
        status.text(f"ğŸ” {ticker} ë¶„ì„ ì¤‘ ({i+1}/{len(stock_data)})")
        progress.progress((i+1)/len(stock_data))
        
        with debug_container:
            st.info(f"ğŸš€ {ticker} í¬ë¡¤ë§ ë° LLM ë¶„ì„ ì‹œì‘...")
        
        try:
            # í¬ë¡¤ë§ ë‹¨ê³„ ë””ë²„ê¹…
            with debug_container:
                st.write(f"ğŸ“¡ {ticker} í¬ë¡¤ë§ ì¤‘...")
            articles, links, debug = crawl_info(ticker, start_date)
            
            with debug_container:
                st.success(f"âœ… {ticker} í¬ë¡¤ë§ ì™„ë£Œ: {len(articles)}ê°œ ê¸°ì‚¬ ìˆ˜ì§‘")
                if len(articles) > 0:
                    st.write(f"ì²« ë²ˆì§¸ ê¸°ì‚¬ ìƒ˜í”Œ: {articles[0][:100]}...")
                
            # LLM ë¶„ì„ ë‹¨ê³„ ë””ë²„ê¹…
            with debug_container:
                st.write(f"ğŸ§  {ticker} LLM ë¶„ì„ ì¤‘...")
            recommendation, review_content = run_llm(ticker, start_date, item['Return (%)'], articles, language)
            
            with debug_container:
                st.success(f"âœ… {ticker} LLM ë¶„ì„ ì™„ë£Œ")
                if recommendation:
                    st.write(f"LLM ì‘ë‹µ ìƒ˜í”Œ: {recommendation[:100]}...")
                else:
                    st.warning(f"âš ï¸ {ticker} LLM ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
            
            # í¬ë¡¤ë§ ìš”ì•½ ë° ì£¼ì‹ ë¶„ì„ ì¶”ê°€
            crawling_summary = summarize_crawling_process(articles, debug)
            stock_analysis = analyze_stock_characteristics(
                ticker, 
                item['Return (%)'], 
                item['Risk (%)'], 
                start_date,
                '2024-12-31'
            )
        
        except Exception as e:
            with debug_container:
                st.error(f"âŒ {ticker} ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                st.write(f"ì˜¤ë¥˜ ì„¸ë¶€ì‚¬í•­: {type(e).__name__}")
            
            # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ê°’ ì„¤ì •
            articles, links, debug = [], [], [f"Error: {str(e)}"]
            recommendation = f"ë¶„ì„ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            review_content = recommendation
            crawling_summary = {"data_quality": "ì˜¤ë¥˜", "total_sources": 0}
            stock_analysis = {"ticker": ticker, "investment_strategy": {"strategy": "ë¶„ì„ ë¶ˆê°€"}}
        
        # ë¶„ì„ ê²°ê³¼ ì €ì¥
        
        reasons.append({
            **item, 
            'ì¶”ì²œ ì‚¬ìœ ': recommendation, 
            'í¬ë¡¤ë§ ë””ë²„ê·¸': debug, 
            'ì°¸ê³  ë§í¬': links, 
            'í¬ë¡¤ë§ëœ ê¸°ì‚¬': articles, 
            'ë¦¬ë·° ë‚´ìš©': review_content,
            'í¬ë¡¤ë§ ìš”ì•½': crawling_summary,
            'ì£¼ì‹ ë¶„ì„': stock_analysis
        })
    progress.empty(); status.empty()
    st.subheader("ğŸ“‹ ì¢…ëª© ì¶”ì²œ ìš”ì•½")
    for idx, r in enumerate(reasons):
        with st.expander(f"#{idx+1} {r['Ticker']} - ìˆ˜ìµë¥ : {r['Return (%)']:.2f}%", expanded= idx<3):
            c1, c2 = st.columns([1,3])
            with c1:
                st.metric("ìˆ˜ìµë¥ ", f"{r['Return (%)']:.2f}%")
                st.metric("ë¦¬ìŠ¤í¬", f"{r['Risk (%)']:.2f}%")
            with c2:
                st.write("**AI ë¶„ì„ ê²°ê³¼:**")
                st.write(r['ì¶”ì²œ ì‚¬ìœ '])
                
                # ë”¥ëŸ¬ë‹ ëª¨ë¸ ì¶”ì²œ ì„¹ì…˜
                with st.expander("ğŸ§  ë”¥ëŸ¬ë‹ ëª¨ë¸ ì¶”ì²œ", expanded=False):
                    analysis = r['ì£¼ì‹ ë¶„ì„']
                    st.write(f"**ì¶”ì²œ ëª¨ë¸:** {analysis['primary_model']['model']}")
                    st.write(f"**ì„ íƒ ì´ìœ :** {analysis['primary_model']['reason']}")
                    st.write(f"**ëŒ€ì•ˆ ëª¨ë¸:** {analysis['secondary_model']['model']}")
                    st.write(f"**ëŒ€ì•ˆ ì´ìœ :** {analysis['secondary_model']['reason']}")
                    
                    st.write("**íˆ¬ì ì „ëµ ì œì•ˆ:**")
                    strategy = analysis['investment_strategy']
                    st.write(f"â€¢ **ì „ëµ:** {strategy['strategy']}")
                    st.write(f"â€¢ **ì„¤ëª…:** {strategy['description']}")
                    st.write(f"â€¢ **ëª©í‘œ ê¸°ê°„:** {strategy['target_period']}")
                    st.write(f"â€¢ **ë¦¬ìŠ¤í¬ ê´€ë¦¬:** {strategy['risk_management']}")
                
                # í¬ë¡¤ë§ ë°ì´í„° ìš”ì•½ ì„¹ì…˜
                with st.expander("ğŸ“Š í¬ë¡¤ë§ ë°ì´í„° ìš”ì•½", expanded=False):
                    summary = r['í¬ë¡¤ë§ ìš”ì•½']
                    col1, col2 = st.columns(2)
                    with col1:
                        st.metric("ì´ ì†ŒìŠ¤", summary.get('total_sources', 0))
                        st.metric("ì„±ê³µí•œ í¬ë¡¤ë§", summary.get('successful_crawls', 0))
                        st.metric("Google Finance", summary.get('google_finance', 0))
                    with col2:
                        st.metric("Yahoo Finance", summary.get('yahoo_finance', 0))
                        st.metric("MarketWatch", summary.get('marketwatch', 0))
                        st.metric("RSS í”¼ë“œ", summary.get('rss_feeds', 0))
                    
                    st.write(f"**ë°ì´í„° í’ˆì§ˆ:** {summary.get('data_quality', 'ì•Œ ìˆ˜ ì—†ìŒ')}")
                    if summary.get('fallback_used'):
                        st.warning("âš ï¸ í´ë°± ì½˜í…ì¸ ê°€ ì‚¬ìš©ë˜ì—ˆìŠµë‹ˆë‹¤")
                    
                    if 'article_breakdown' in summary:
                        st.write("**ê¸°ì‚¬ ë¶„ì„:**")
                        for source, count in summary['article_breakdown'].items():
                            st.write(f"â€¢ {source}: {count}ê°œ")
                    
                    st.write("**ì²˜ë¦¬ ê³¼ì •:**")
                    for step in summary.get('processing_steps', []):
                        st.write(f"â€¢ {step}")
                
                with st.expander("ğŸ” í¬ë¡¤ë§ ê²€ì¦ ì •ë³´", expanded=False):
                    st.write("**ë””ë²„ê·¸:**")
                    for d in r['í¬ë¡¤ë§ ë””ë²„ê·¸']:
                        st.text(d)
                    st.write("**í¬ë¡¤ë§ëœ ê¸°ì‚¬ ë‚´ìš©:**")
                    for idx, art in enumerate(r['í¬ë¡¤ë§ëœ ê¸°ì‚¬'][:NUM_REFERENCES]): 
                        st.write(f"**ê¸°ì‚¬ {idx+1}:** {art[:200]}...")
                if r['ì°¸ê³  ë§í¬']:
                    st.write("**ì°¸ê³  ë§í¬:**")
                    for idx, l in enumerate(r['ì°¸ê³  ë§í¬'][:NUM_REFERENCES]): 
                        if l and l.startswith('http'):
                            st.markdown(f"ğŸ”— [ì°¸ê³ ìë£Œ {idx+1}]({l})")
                # LLMì´ ë¦¬ë·°í•œ ë‚´ìš© í† ê¸€ë¡œ í‘œì‹œ
                with st.expander("ğŸ“ LLM ë¦¬ë·° ë‚´ìš©", expanded=False):
                    st.write(r['ë¦¬ë·° ë‚´ìš©'])
    
    # í¬ë¡¤ë§ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
    st.subheader("ğŸ” í¬ë¡¤ë§ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸")
    with st.expander("í¬ë¡¤ë§ í…ŒìŠ¤íŠ¸ ì‹¤í–‰", expanded=False):
        if st.button("í¬ë¡¤ë§ í…ŒìŠ¤íŠ¸ ì‹œì‘"):
            test_ticker = "AAPL"
            st.write(f"ğŸ§ª {test_ticker}ë¡œ í¬ë¡¤ë§ í…ŒìŠ¤íŠ¸ ì¤‘...")
            
            try:
                test_articles, test_links, test_debug = crawl_info(test_ticker, start_date)
                
                st.success(f"âœ… í¬ë¡¤ë§ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
                st.write(f"ìˆ˜ì§‘ëœ ê¸°ì‚¬: {len(test_articles)}ê°œ")
                st.write(f"ì°¸ê³  ë§í¬: {len(test_links)}ê°œ")
                st.write(f"ë””ë²„ê·¸ ì •ë³´: {len(test_debug)}ê°œ")
                
                if test_articles:
                    st.write("ì²« ë²ˆì§¸ ê¸°ì‚¬ ìƒ˜í”Œ:")
                    st.text(test_articles[0][:200])
                
                st.write("ë””ë²„ê·¸ ì •ë³´:")
                for debug_item in test_debug[:5]:
                    st.text(debug_item)
                    
            except Exception as e:
                st.error(f"âŒ í¬ë¡¤ë§ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")
                import traceback
                st.text(traceback.format_exc())

            # ë¶„ì„ ê²°ê³¼ ìƒì„¸ ë””ë²„ê¹… ì •ë³´ í‘œì‹œ
            with debug_container:
                if recommendation and "Error" not in recommendation:
                    st.success(f"ğŸ¯ {ticker} ì „ì²´ ë¶„ì„ ì„±ê³µ!")
                else:
                    st.error(f"ğŸš¨ {ticker} ë¶„ì„ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤")
                
                # ë¶„ì„ í†µê³„
                st.write("ğŸ“Š ë¶„ì„ í†µê³„:")
                st.write(f"   â€¢ í¬ë¡¤ë§ëœ ê¸°ì‚¬: {len(articles)}ê°œ")
                st.write(f"   â€¢ ì°¸ê³  ë§í¬: {len(links)}ê°œ")
                st.write(f"   â€¢ LLM ì‘ë‹µ ê¸¸ì´: {len(recommendation) if recommendation else 0}ì")
                st.write(f"   â€¢ ë°ì´í„° í’ˆì§ˆ: {crawling_summary.get('data_quality', 'ì•Œ ìˆ˜ ì—†ìŒ')}")
