import streamlit as st
import pandas as pd
import yfinance as yf
import plotly.graph_objects as go

from modules.crawler import crawl_info_parallel
from modules.llm_handler import run_llm, run_llm_stock_analysis, run_llm_with_enhanced_content, check_vllm_server, test_vllm_simple
from modules.stock_analyzer import analyze_stock_characteristics, summarize_crawling_process, explain_llm_processing_logic
from modules.content_extractor import extract_content_from_url # ì¶”ê°€
from config import NUM_REFERENCES, CONFIG_LANGUAGES

# UI Components

def header_ui():
    st.markdown("""
    <div style="background: linear-gradient(90deg, #667eea 0%, #764ba2 100%); padding: 2rem; border-radius: 10px; margin-bottom: 2rem;">
        <h1 style="color: white; text-align: center; margin: 0;">ğŸ“ˆ AI ê¸°ë°˜ í¬íŠ¸í´ë¦¬ì˜¤ ì¶”ì²œ ë¦¬ì„œì¹˜ ë„ìš°ë¯¸</h1>
        <p style="color: white; text-align: center; margin: 0.5rem 0 0 0;">S&P500 ì¢…ëª© ë¶„ì„ ë° AI ê¸°ë°˜ íˆ¬ì ì‚¬ìœ  ë¶„ì„</p>
    </div>
    """, unsafe_allow_html=True)


def sidebar_ui(default_start, default_end):
    st.sidebar.header("ğŸ”§ ë¶„ì„ ì„¤ì •")
    with st.sidebar.expander("ğŸ“… íˆ¬ì ê¸°ê°„ ì„¤ì •", expanded=True):
        start_date = st.date_input("íˆ¬ì ì‹œì‘ì¼:", value=default_start)
        end_date = st.date_input("íˆ¬ì ì¢…ë£Œì¼:", value=default_end)
    with st.sidebar.expander("ğŸ¯ ë¶„ì„ ì¡°ê±´", expanded=True):
        target_return = st.slider("ëª©í‘œ ìˆ˜ìµë¥  (%)", 0.0, 100.0, 10.0, 0.5)
        top_n = st.select_slider("ì¶”ì²œ ì¢…ëª© ìˆ˜", list(range(1,21)), 5)
    # Language selection for LLM output
    language = st.sidebar.selectbox("ì–¸ì–´ ì„ íƒ:", options=CONFIG_LANGUAGES, index=0)
    analyze = st.sidebar.button("ğŸš€ ë¶„ì„ ì‹¤í–‰", type="primary")
    if analyze:
        st.session_state.analyze = True
    # vLLM ì„œë²„ ì—°ê²° ìƒíƒœ í™•ì¸ ë²„íŠ¼
    if st.sidebar.button("ğŸ”§ vLLM ì„œë²„ ìƒíƒœ í™•ì¸"):
        from modules.llm_handler import check_vllm_server
        status, message = check_vllm_server()
        if status:
            st.sidebar.success(f"âœ… {message}")
        else:
            st.sidebar.error(f"âŒ {message}")
    return start_date, end_date, target_return, top_n, language


def display_metrics(df):
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("ë¶„ì„ëœ ì¢…ëª© ìˆ˜", len(df), delta="ê°œ")
    with col2:
        st.metric("í‰ê·  ìˆ˜ìµë¥ ", f"{df['Return (%)'].mean():.2f}%")
    with col3:
        st.metric("ìµœê³  ìˆ˜ìµë¥ ", f"{df['Return (%)'].max():.2f}%")
    with col4:
        st.metric("í‰ê·  ë¦¬ìŠ¤í¬", f"{df['Risk (%)'].mean():.2f}%")


def display_table_and_chart(stock_data, start_date, end_date):
    df = pd.DataFrame(stock_data)
    display_df = df.copy()
    display_df['Return (%)'] = display_df['Return (%)'].round(2)
    display_df['Risk (%)'] = display_df['Risk (%)'].round(2)
    col1, col2 = st.columns([1,2])
    with col1:
        st.subheader("ğŸ“Š ì¢…ëª©ë³„ ìˆ˜ìµë¥  & ë¦¬ìŠ¤í¬")
        st.dataframe(display_df, use_container_width=True)
    with col2:
        st.subheader("ğŸ“ˆ í¬íŠ¸í´ë¦¬ì˜¤ ì£¼ê°€ ì°¨íŠ¸")
        
        # Chart period selection
        chart_period = st.selectbox("ì°¨íŠ¸ ì£¼ê¸° ì„ íƒ", ["ì¼ë´‰","ì£¼ë´‰","ì›”ë´‰"], index=0, key="chart_period")
        
        # Moving Average trend line options
        st.write("**ì´ë™í‰ê· ì„  ì„¤ì •:**")
        ma_cols = st.columns(4)
        show_ma = {}
        with ma_cols[0]:
            show_ma[5] = st.checkbox("MA5", value=True, key="ma5")
        with ma_cols[1]:
            show_ma[20] = st.checkbox("MA20", value=True, key="ma20")
        with ma_cols[2]:
            show_ma[60] = st.checkbox("MA60", value=False, key="ma60")
        with ma_cols[3]:
            show_ma[120] = st.checkbox("MA120", value=False, key="ma120")
        
        # Stock selection checkboxes
        st.write("**í‘œì‹œí•  ì¢…ëª© ì„ íƒ:**")
        selected_stocks = []
        cols = st.columns(min(3, len(stock_data)))  # Create up to 3 columns
        
        for i, item in enumerate(stock_data):
            with cols[i % 3]:
                if st.checkbox(
                    item['Ticker'], 
                    value=True, 
                    key=f"stock_select_{item['Ticker']}"
                ):
                    selected_stocks.append(item)
        
        if not selected_stocks:
            st.warning("âš ï¸ ì ì–´ë„ í•˜ë‚˜ì˜ ì¢…ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
            return
            
        # Color palette for better visual separation
        colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']
            
        with st.spinner('ğŸ“ˆ í¬íŠ¸í´ë¦¬ì˜¤ ì„±ê³¼ ê³„ì‚° ì¤‘...'):
            fig = go.Figure()
            
            # Process each selected stock with unique colors
            for idx, item in enumerate(selected_stocks):
                base_color = colors[idx % len(colors)]
                data = yf.Ticker(item['Ticker']).history(start=str(start_date), end=str(end_date))
                
                # Check if data is available
                if data.empty:
                    st.warning(f"âš ï¸ {item['Ticker']} ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    continue
                
                # Resample data based on selected period
                if chart_period == "ì£¼ë´‰":
                    # Use 'W-FRI' for weekly data ending on Friday
                    data = data.resample('W-FRI').agg({
                        'Open':'first',
                        'High':'max',
                        'Low':'min',
                        'Close':'last',
                        'Volume':'sum'
                    }).dropna()
                elif chart_period == "ì›”ë´‰":
                    # Use 'M' for monthly data ending on last day of month
                    data = data.resample('M').agg({
                        'Open':'first',
                        'High':'max',
                        'Low':'min',
                        'Close':'last',
                        'Volume':'sum'
                    }).dropna()
                
                # Check if resampled data is available
                if data.empty:
                    st.warning(f"âš ï¸ {item['Ticker']} {chart_period} ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                    continue
                
                # Use Candlestick chart with custom colors
                fig.add_trace(go.Candlestick(
                    x=data.index,
                    open=data['Open'],
                    high=data['High'],
                    low=data['Low'],
                    close=data['Close'],
                    name=f"{item['Ticker']} ìº”ë“¤",
                    increasing_line_color=base_color,
                    decreasing_line_color=base_color,
                    increasing_fillcolor=base_color,
                    decreasing_fillcolor=base_color,
                    opacity=0.8
                ))
                
                # Add Moving Average trend lines with coordinated colors
                ma_config = {
                    5: {'color': f"rgba({int(base_color[1:3], 16)}, {int(base_color[3:5], 16)}, {int(base_color[5:7], 16)}, 0.9)", 'style': 'solid', 'width': 1.5},
                    20: {'color': f"rgba({int(base_color[1:3], 16)}, {int(base_color[3:5], 16)}, {int(base_color[5:7], 16)}, 0.7)", 'style': 'dash', 'width': 2},
                    60: {'color': f"rgba({int(base_color[1:3], 16)}, {int(base_color[3:5], 16)}, {int(base_color[5:7], 16)}, 0.5)", 'style': 'dot', 'width': 2.5},
                    120: {'color': f"rgba({int(base_color[1:3], 16)}, {int(base_color[3:5], 16)}, {int(base_color[5:7], 16)}, 0.3)", 'style': 'dashdot', 'width': 3}
                }
                
                ma_names = {5: 'MA5', 20: 'MA20', 60: 'MA60', 120: 'MA120'}
                
                for period in [5, 20, 60, 120]:
                    if show_ma.get(period, False) and len(data) >= period:
                        ma_values = data['Close'].rolling(window=period).mean()
                        config = ma_config[period]
                        
                        fig.add_trace(go.Scatter(
                            x=data.index,
                            y=ma_values,
                            mode='lines',
                            name=f'{item["Ticker"]} {ma_names[period]}',
                            line=dict(
                                color=config['color'], 
                                width=config['width'], 
                                dash=config['style']
                            ),
                            opacity=0.8,
                            hovertemplate=f'<b>{item["Ticker"]} {ma_names[period]}</b><br>' +
                                        'Date: %{x}<br>' +
                                        f'{ma_names[period]}: $%{{y:.2f}}<br>' +
                                        '<extra></extra>'
                        ))
            fig.update_layout(
                title=f"{chart_period} ì£¼ê°€ ì°¨íŠ¸ ({len(selected_stocks)}ê°œ ì¢…ëª©)", 
                xaxis_title="ë‚ ì§œ", 
                yaxis_title="ì£¼ê°€ ($)", 
                hovermode='x unified', 
                height=800,  # Increased height for better visibility
                showlegend=True, 
                legend=dict(
                    orientation="v", 
                    yanchor="top", 
                    y=1, 
                    xanchor="left", 
                    x=1.01,
                    bgcolor="rgba(255,255,255,0.8)",
                    bordercolor="rgba(0,0,0,0.2)",
                    borderwidth=1
                ),
                margin=dict(r=200),  # Add right margin for legend
                xaxis=dict(
                    rangeslider=dict(visible=True, thickness=0.05),
                    rangeselector=dict(
                        buttons=list([
                            dict(count=7, label="7D", step="day", stepmode="backward"),
                            dict(count=30, label="1M", step="day", stepmode="backward"),
                            dict(count=90, label="3M", step="day", stepmode="backward"),
                            dict(count=180, label="6M", step="day", stepmode="backward"),
                            dict(label="ì „ì²´", step="all")
                        ])
                    )
                ),
                dragmode='zoom',  # Enable zoom functionality
                plot_bgcolor='rgba(240,240,240,0.3)',  # Light background
                paper_bgcolor='white'
            )
            
            # Add custom controls description
            st.info("ğŸ’¡ **ì°¨íŠ¸ ì¡°ì‘ë²•:** ë“œë˜ê·¸ë¡œ í™•ëŒ€, ë”ë¸”í´ë¦­ìœ¼ë¡œ ì „ì²´ë³´ê¸°, ë²”ìœ„ì„ íƒ ë²„íŠ¼ í™œìš©")
            st.plotly_chart(fig, use_container_width=True)


def display_risk_info():
    with st.expander("ğŸ“Š ë¦¬ìŠ¤í¬(Risk) ê³„ì‚° ë°©ë²•", expanded=False):
        st.markdown("""
        **ë¦¬ìŠ¤í¬ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ê³„ì‚°ë©ë‹ˆë‹¤:**
        1. **ì¼ë³„ ìˆ˜ìµë¥  ê³„ì‚°**: ì¢…ê°€ ê¸°ì¤€ ìˆ˜ìµë¥  ê³„ì‚°
        2. **í‘œì¤€í¸ì°¨ ê³„ì‚°**: ì¼ë³„ ìˆ˜ìµë¥ ë“¤ì˜ í‘œì¤€í¸ì°¨
        3. **ë°±ë¶„ìœ¨ ë³€í™˜**: í‘œì¤€í¸ì°¨ì— 100 ê³±í•¨
        **í•´ì„:**
        - ë‚®ì€ ë¦¬ìŠ¤í¬ (<2%): ì•ˆì •ì 
        - ì¤‘ê°„ ë¦¬ìŠ¤í¬ (2-5%): ë³´í†µ
        - ë†’ì€ ë¦¬ìŠ¤í¬ (>5%): ë³€ë™ì„± ë†’ìŒ
        """, unsafe_allow_html=True)


def display_ai_analysis(stock_data, start_date, language):
    st.markdown("---")
    st.header("ğŸ¤– AI íˆ¬ì ì‚¬ìœ  ë¶„ì„")
    
    # vLLM ì„œë²„ ìƒíƒœ í™•ì¸ - í† ê¸€ë¡œ ë³€ê²½
    with st.expander("ğŸ”§ ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸", expanded=False):
        with st.spinner("vLLM ì„œë²„ ì—°ê²° í™•ì¸ ì¤‘..." if language == "í•œêµ­ì–´" else "Checking vLLM server connection..."):
            vllm_status, vllm_message = check_vllm_server()
            
            if vllm_status:
                success_msg = f"âœ… {vllm_message}" if language == "í•œêµ­ì–´" else f"âœ… vLLM Server Connected: {vllm_message}"
                st.success(success_msg)
                
                # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ìˆ˜í–‰
                test_status, test_message = test_vllm_simple()
                if test_status:
                    test_success_msg = f"âœ… vLLM í…ŒìŠ¤íŠ¸: {test_message}" if language == "í•œêµ­ì–´" else f"âœ… vLLM Test: {test_message}"
                    st.success(test_success_msg)
                else:
                    test_fail_msg = f"âš ï¸ vLLM í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {test_message}" if language == "í•œêµ­ì–´" else f"âš ï¸ vLLM Test Failed: {test_message}"
                    st.warning(test_fail_msg)
            else:
                error_msg = f"âŒ {vllm_message}" if language == "í•œêµ­ì–´" else f"âŒ vLLM Server Error: {vllm_message}"
                st.error(error_msg)
                
                if language == "í•œêµ­ì–´":
                    st.error("vLLM ì„œë²„ë¥¼ ì‹œì‘í•´ì£¼ì„¸ìš”. í„°ë¯¸ë„ì—ì„œ ë‹¤ìŒ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”:")
                    st.code("python -m vllm.entrypoints.openai.api_server --model TinyLlama/TinyLlama-1.1B-Chat-v1.0 --port 8000")
                    st.info("ğŸ’¡ WSL í™˜ê²½ì—ì„œëŠ” scripts/wsl/start_vllm.sh ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                else:
                    st.error("Please start the vLLM server. Run the following command in terminal:")
                    st.code("python -m vllm.entrypoints.openai.api_server --model TinyLlama/TinyLlama-1.1B-Chat-v1.0 --port 8000")
                    st.info("ğŸ’¡ For WSL environment, you can use the scripts/wsl/start_vllm.sh script.")
                st.stop()
    
    # LLM ì²˜ë¦¬ ë¡œì§ ì„¤ëª…
    with st.expander("ğŸ§  LLM ë°ì´í„° ì²˜ë¦¬ ë¡œì§", expanded=False):
        llm_logic = explain_llm_processing_logic()
        
        st.subheader("ğŸ“¥ ì…ë ¥ ë°ì´í„° ì²˜ë¦¬")
        for step in llm_logic["input_processing"]:
            st.write(f"â€¢ {step}")
        
        st.subheader("ğŸ” ë¶„ì„ ë°©ë²•ë¡ ")
        for method in llm_logic["analysis_methodology"]:
            st.write(f"â€¢ {method}")
        
        st.subheader("ğŸ“¤ ê²°ê³¼ ìƒì„±")
        for output in llm_logic["output_generation"]:
            st.write(f"â€¢ {output}")
        
        st.subheader("âœ… í’ˆì§ˆ ë³´ì¦")
        for qa in llm_logic["quality_assurance"]:
            st.write(f"â€¢ {qa}")
    
    # ë””ë²„ê¹… ì •ë³´ í‘œì‹œ
    with st.expander("ğŸ“ˆ ì‹¤ì‹œê°„ ë¶„ì„ ë¡œê·¸", expanded=False):
        debug_container = st.container()
    
    progress = st.progress(0)
    status = st.empty()
    reasons = []
    
    for i, item in enumerate(stock_data):
        ticker = item['Ticker']
        status.text(f"ğŸ” {ticker} ë¶„ì„ ì¤‘ ({i+1}/{len(stock_data)})")
        progress.progress((i+1)/len(stock_data))
        
        with debug_container:
            st.info(f"ğŸš€ {ticker} í¬ë¡¤ë§ ë° LLM ë¶„ì„ ì‹œì‘...")
        
        try:
            # í¬ë¡¤ë§ ë‹¨ê³„ ë””ë²„ê¹…
            with debug_container:
                st.write(f"ğŸ“¡ {ticker} í¬ë¡¤ë§ ì¤‘...")
            articles, links, debug = crawl_info_parallel(ticker, start_date)
            
            with debug_container:
                st.success(f"âœ… {ticker} í¬ë¡¤ë§ ì™„ë£Œ: {len(articles)}ê°œ ê¸°ì‚¬ ìˆ˜ì§‘")
                if len(articles) > 0:
                    st.write(f"ì²« ë²ˆì§¸ ê¸°ì‚¬ ìƒ˜í”Œ: {articles[0][:100]}...")
                
            # LLM ë¶„ì„ ë‹¨ê³„ ë””ë²„ê¹… (Enhanced with link content)
            with debug_container:
                st.write(f"ğŸ§  {ticker} ê°•í™”ëœ LLM ë¶„ì„ ì¤‘...")
            
            # Use enhanced LLM analysis with link content extraction
            recommendation, review_content, extraction_debug = run_llm_with_enhanced_content(
                ticker, start_date, item['Return (%)'], articles, links, language
            )
            
            with debug_container:
                st.success(f"âœ… {ticker} ê°•í™”ëœ LLM ë¶„ì„ ì™„ë£Œ")
                if recommendation:
                    st.write(f"LLM ì‘ë‹µ ìƒ˜í”Œ: {recommendation[:100]}...")
                    if extraction_debug:
                        st.write(f"ë§í¬ ì¶”ì¶œ ì •ë³´: {len(extraction_debug)}ê°œ ë””ë²„ê·¸ í•­ëª©")
                else:
                    st.warning(f"âš ï¸ {ticker} LLM ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
            
            # í¬ë¡¤ë§ ìš”ì•½ ë° ì£¼ì‹ ë¶„ì„ ì¶”ê°€
            crawling_summary = summarize_crawling_process(articles, debug)
            stock_analysis = analyze_stock_characteristics(
                ticker, 
                item['Return (%)'], 
                item['Risk (%)'], 
                start_date,
                '2024-12-31'
            )
        
        except Exception as e:
            with debug_container:
                st.error(f"âŒ {ticker} ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                st.write(f"ì˜¤ë¥˜ ì„¸ë¶€ì‚¬í•­: {type(e).__name__}")
            
            # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ê°’ ì„¤ì •
            articles, links, debug = [], [], [f"Error: {str(e)}"]
            recommendation = f"ë¶„ì„ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            review_content = recommendation
            extraction_debug = [f"Error during extraction: {str(e)}"]
            crawling_summary = {"data_quality": "ì˜¤ë¥˜", "total_sources": 0}
            stock_analysis = {"ticker": ticker, "investment_strategy": {"strategy": "ë¶„ì„ ë¶ˆê°€"}}
        
        # ë¶„ì„ ê²°ê³¼ ì €ì¥
        
        reasons.append({
            **item, 
            'ì¶”ì²œ ì‚¬ìœ ': recommendation, 
            'í¬ë¡¤ë§ ë””ë²„ê·¸': debug, 
            'ì°¸ê³  ë§í¬': links, 
            'í¬ë¡¤ë§ëœ ê¸°ì‚¬': articles, 
            'ë¦¬ë·° ë‚´ìš©': review_content,
            'í¬ë¡¤ë§ ìš”ì•½': crawling_summary,
            'ì£¼ì‹ ë¶„ì„': stock_analysis,
            'ë§í¬ ì¶”ì¶œ ë””ë²„ê·¸': extraction_debug if 'extraction_debug' in locals() else []
        })
    progress.empty(); status.empty()
    
    # ìˆ˜ì§‘ëœ ì •ë³´ ìš”ì•½ ì„¹ì…˜ ì¶”ê°€
    with st.expander("ğŸ“‹ ìˆ˜ì§‘ëœ ì •ë³´ ìš”ì•½", expanded=True):
        generate_collected_info_summary(reasons, language, vllm_status)
    
    st.subheader("ğŸ“‹ ì¢…ëª© ì¶”ì²œ ìš”ì•½")
    for idx, r in enumerate(reasons):
        with st.expander(f"#{idx+1} {r['Ticker']} - ìˆ˜ìµë¥ : {r['Return (%)']:.2f}%", expanded= idx<3):
            c1, c2 = st.columns([1,3])
            with c1:
                st.metric("ìˆ˜ìµë¥ ", f"{r['Return (%)']:.2f}%")
                st.metric("ë¦¬ìŠ¤í¬", f"{r['Risk (%)']:.2f}%")
            with c2:
                st.write("**AI ë¶„ì„ ê²°ê³¼:**")
                st.write(r['ì¶”ì²œ ì‚¬ìœ '])
                
                # ë”¥ëŸ¬ë‹ ëª¨ë¸ ì¶”ì²œ ì„¹ì…˜
                with st.expander("ğŸ§  ë”¥ëŸ¬ë‹ ëª¨ë¸ ì¶”ì²œ", expanded=False):
                    analysis = r['ì£¼ì‹ ë¶„ì„']
                    st.write(f"**ì¶”ì²œ ëª¨ë¸:** {analysis['primary_model']['model']}")
                    st.write(f"**ì„ íƒ ì´ìœ :** {analysis['primary_model']['reason']}")
                    st.write(f"**ëŒ€ì•ˆ ëª¨ë¸:** {analysis['secondary_model']['model']}")
                    st.write(f"**ëŒ€ì•ˆ ì´ìœ :** {analysis['secondary_model']['reason']}")
                    
                    st.write("**íˆ¬ì ì „ëµ ì œì•ˆ:**")
                    strategy = analysis['investment_strategy']
                    st.write(f"â€¢ **ì „ëµ:** {strategy['strategy']}")
                    st.write(f"â€¢ **ì„¤ëª…:** {strategy['description']}")
                    st.write(f"â€¢ **ëª©í‘œ ê¸°ê°„:** {strategy['target_period']}")
                    st.write(f"â€¢ **ë¦¬ìŠ¤í¬ ê´€ë¦¬:** {strategy['risk_management']}")
                
                # í¬ë¡¤ë§ ë°ì´í„° ìš”ì•½ ì„¹ì…˜
                with st.expander("ğŸ“Š í¬ë¡¤ë§ ë°ì´í„° ìš”ì•½", expanded=False):
                    summary = r['í¬ë¡¤ë§ ìš”ì•½']
                    col1, col2 = st.columns(2)
                    with col1:
                        st.metric("ì´ ì†ŒìŠ¤", summary.get('total_sources', 0))
                        st.metric("ì„±ê³µí•œ í¬ë¡¤ë§", summary.get('successful_crawls', 0))
                        st.metric("Google Finance", summary.get('google_finance', 0))
                    with col2:
                        st.metric("Yahoo Finance", summary.get('yahoo_finance', 0))
                        st.metric("MarketWatch", summary.get('marketwatch', 0))
                        st.metric("RSS í”¼ë“œ", summary.get('rss_feeds', 0))
                    
                    st.write(f"**ë°ì´í„° í’ˆì§ˆ:** {summary.get('data_quality', 'ì•Œ ìˆ˜ ì—†ìŒ')}")
                    if summary.get('fallback_used'):
                        st.warning("âš ï¸ í´ë°± ì½˜í…ì¸ ê°€ ì‚¬ìš©ë˜ì—ˆìŠµë‹ˆë‹¤")
                    
                    if 'article_breakdown' in summary:
                        st.write("**ê¸°ì‚¬ ë¶„ì„:**")
                        for source, count in summary['article_breakdown'].items():
                            st.write(f"â€¢ {source}: {count}ê°œ")
                    
                    st.write("**ì²˜ë¦¬ ê³¼ì •:**")
                    for step in summary.get('processing_steps', []):
                        st.write(f"â€¢ {step}")
                
                with st.expander("ğŸ” í¬ë¡¤ë§ ê²€ì¦ ì •ë³´", expanded=False):
                    st.write("**ë””ë²„ê·¸:**")
                    for d in r['í¬ë¡¤ë§ ë””ë²„ê·¸']:
                        st.text(d)
                    st.write("**í¬ë¡¤ë§ëœ ê¸°ì‚¬ ë‚´ìš©:**")
                    for idx, art in enumerate(r['í¬ë¡¤ë§ëœ ê¸°ì‚¬'][:NUM_REFERENCES]): 
                        st.write(f"**ê¸°ì‚¬ {idx+1}:** {art[:200]}...")
                if r['ì°¸ê³  ë§í¬']:
                    st.write("**ì°¸ê³  ë§í¬:**")
                    for idx, l in enumerate(r['ì°¸ê³  ë§í¬'][:NUM_REFERENCES]): 
                        if l and l.startswith('http'):
                            st.markdown(f"ğŸ”— [ì°¸ê³ ìë£Œ {idx+1}]({l})")
                # LLMì´ ë¦¬ë·°í•œ ë‚´ìš© í† ê¸€ë¡œ í‘œì‹œ
                with st.expander("ğŸ“ LLM ë¦¬ë·° ë‚´ìš©", expanded=False):
                    st.write(r['ë¦¬ë·° ë‚´ìš©'])
                
                # ê°•í™”ëœ ë§í¬ ë¶„ì„ ì •ë³´ í‘œì‹œ
                if r.get('ë§í¬ ì¶”ì¶œ ë””ë²„ê·¸'):
                    with st.expander("ğŸ”— ê°•í™”ëœ ë§í¬ ë¶„ì„", expanded=False):
                        st.write("**ë§í¬ ì½˜í…ì¸  ì¶”ì¶œ ê³¼ì •:**")
                        for debug_item in r['ë§í¬ ì¶”ì¶œ ë””ë²„ê·¸']:
                            st.text(debug_item)
                        
                        st.info("ğŸ’¡ ìƒìœ„ ê´€ë ¨ì„± ë§í¬ì—ì„œ ì¶”ê°€ ì½˜í…ì¸ ë¥¼ ì¶”ì¶œí•˜ì—¬ ë” ìƒì„¸í•œ íˆ¬ì ë¶„ì„ì„ ì œê³µí–ˆìŠµë‹ˆë‹¤.")
    
def display_crawling_test_ui(start_date, language):
    """UI for crawling test tab."""
    st.subheader("ğŸ” í¬ë¡¤ë§ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸")
    
    # ì¢…ëª© í‹°ì»¤ ê¸°ë°˜ í…ŒìŠ¤íŠ¸
    st.write("**ì¢…ëª© í‹°ì»¤ ê¸°ë°˜ í¬ë¡¤ë§ í…ŒìŠ¤íŠ¸:**")
    if st.button("AAPL í‹°ì»¤ë¡œ í…ŒìŠ¤íŠ¸"):
        st.session_state.run_ticker_test = True
        st.session_state.ticker_test_results = None

    if st.session_state.get('run_ticker_test'):
        with st.spinner("AAPL í¬ë¡¤ë§ ì¤‘..."):
            try:
                articles, links, debug = crawl_info_parallel("AAPL", start_date)
                st.session_state.ticker_test_results = {"success": True, "articles": articles, "links": links, "debug": debug}
            except Exception as e:
                import traceback
                st.session_state.ticker_test_results = {"success": False, "error": str(e), "traceback": traceback.format_exc()}
        st.session_state.run_ticker_test = False
        st.rerun()

    if st.session_state.get('ticker_test_results'):
        res = st.session_state.ticker_test_results
        if res["success"]:
            st.success("âœ… AAPL í¬ë¡¤ë§ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
            st.write(f"ìˆ˜ì§‘ëœ ê¸°ì‚¬: {len(res['articles'])}ê°œ, ë§í¬: {len(res['links'])}ê°œ")
            with st.expander("ìƒì„¸ ê²°ê³¼ ë³´ê¸°"):
                st.json(res)
        else:
            st.error(f"âŒ AAPL í¬ë¡¤ë§ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {res['error']}")

    st.markdown("---")
    
    # URL ê¸°ë°˜ ì½˜í…ì¸  ìš”ì•½ í…ŒìŠ¤íŠ¸
    st.write("**URL ê¸°ë°˜ ì½˜í…ì¸  ìš”ì•½ í…ŒìŠ¤íŠ¸:**")
    test_url = st.text_input("í…ŒìŠ¤íŠ¸í•  ê¸°ì‚¬ URLì„ ì…ë ¥í•˜ì„¸ìš”:", key="test_url")
    
    if st.button("URL ì½˜í…ì¸  ìš”ì•½ ì‹¤í–‰"):
        st.session_state.run_url_summary_test = True
        st.session_state.url_summary_results = None

    if st.session_state.get('run_url_summary_test') and test_url:
        with st.spinner("URL ì½˜í…ì¸  ì¶”ì¶œ ë° ìš”ì•½ ì¤‘..."):
            try:
                # 1. ì½˜í…ì¸  ì¶”ì¶œ
                content, _ = extract_content_from_url(test_url)
                
                # 2. LLMìœ¼ë¡œ ìš”ì•½
                if content:
                    if language == "í•œêµ­ì–´":
                        summary_prompt = f"ë‹¤ìŒ ê¸°ì‚¬ì˜ ì£¼ìš” ë‚´ìš©ì„ ìƒì„¸íˆ í•œêµ­ì–´ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”. í•µì‹¬ í¬ì¸íŠ¸, ìˆ˜ì¹˜, ì¤‘ìš”í•œ ì •ë³´ë¥¼ ëª¨ë‘ í¬í•¨í•˜ì—¬ ì¶©ë¶„íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”:\n\n{content}"
                    else:
                        summary_prompt = f"Please provide a detailed summary of the following article in English. Include all key points, numbers, and important information with sufficient explanation:\n\n{content}"
                    
                    summary, _ = run_llm(summary_prompt, "", "URL ìš”ì•½", language)
                    st.session_state.url_summary_results = {"success": True, "content": content, "summary": summary}
                else:
                    st.session_state.url_summary_results = {"success": False, "error": "ì½˜í…ì¸ ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}

            except Exception as e:
                import traceback
                st.session_state.url_summary_results = {"success": False, "error": str(e), "traceback": traceback.format_exc()}
        st.session_state.run_url_summary_test = False
        st.rerun()

    if st.session_state.get('url_summary_results'):
        res = st.session_state.url_summary_results
        if res["success"]:
            st.success("âœ… URL ìš”ì•½ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
            st.write("**ìš”ì•½:**")
            st.write(res['summary'])
            with st.expander("ì¶”ì¶œëœ ì›ë¬¸ ë³´ê¸°"):
                st.text(res['content'])
        else:
            st.error(f"âŒ URL ìš”ì•½ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {res['error']}")
            if "traceback" in res:
                st.text(res['traceback'])

def generate_collected_info_summary(reasons, language, vllm_status):
    """Generate a summary of collected information in the selected language."""
    
    if language == "í•œêµ­ì–´":
        st.subheader("ğŸ“Š ì „ì²´ ë°ì´í„° ìˆ˜ì§‘ í˜„í™©")
        
        if not vllm_status:
            st.error("âš ï¸ vLLM ì„œë²„ ì—°ê²° ë¬¸ì œë¡œ AI ë¶„ì„ì´ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸ì„ í†µí•´ vLLM ì„œë²„ë¥¼ ì‹œì‘í•´ì£¼ì„¸ìš”.")
            st.info("ğŸ’¡ vLLM ì„œë²„ ì—†ì´ë„ í¬ë¡¤ë§ëœ ì •ë³´ëŠ” í™•ì¸í•  ìˆ˜ ìˆì§€ë§Œ, AI ê¸°ë°˜ íˆ¬ì ë¶„ì„ì€ ì œí•œë©ë‹ˆë‹¤.")
        
        # Overall statistics
        total_stocks = len(reasons)
        total_articles = sum(len(r.get('í¬ë¡¤ë§ëœ ê¸°ì‚¬', [])) for r in reasons)
        total_links = sum(len(r.get('ì°¸ê³  ë§í¬', [])) for r in reasons)
        successful_analyses = sum(1 for r in reasons if r.get('ì¶”ì²œ ì‚¬ìœ ') and "Error" not in str(r.get('ì¶”ì²œ ì‚¬ìœ ', '')))
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ë¶„ì„ ì™„ë£Œ ì¢…ëª©", f"{successful_analyses}/{total_stocks}")
        with col2:
            st.metric("ìˆ˜ì§‘ëœ ê¸°ì‚¬", total_articles)
        with col3:
            st.metric("ì°¸ê³  ë§í¬", total_links)
        with col4:
            success_rate = (successful_analyses / total_stocks * 100) if total_stocks > 0 else 0
            st.metric("ì„±ê³µë¥ ", f"{success_rate:.1f}%")
        
        # Data quality summary
        st.write("**ğŸ“ˆ ë°ì´í„° í’ˆì§ˆ ë¶„ì„:**")
        quality_counts = {}
        for r in reasons:
            quality = r.get('í¬ë¡¤ë§ ìš”ì•½', {}).get('data_quality', 'ì•Œ ìˆ˜ ì—†ìŒ')
            quality_counts[quality] = quality_counts.get(quality, 0) + 1
        
        for quality, count in quality_counts.items():
            percentage = (count / total_stocks * 100) if total_stocks > 0 else 0
            st.write(f"â€¢ {quality}: {count}ê°œ ì¢…ëª© ({percentage:.1f}%)")
        
        # Source-wise collection status
        st.write("**ğŸ” ì •ë³´ ì†ŒìŠ¤ë³„ ìˆ˜ì§‘ í˜„í™©:**")
        source_summary = {
            'Google Finance': 0, 'Yahoo Finance': 0, 'MarketWatch': 0, 
            'RSS í”¼ë“œ': 0, 'DuckDuckGo': 0
        }
        
        for r in reasons:
            crawling_summary = r.get('í¬ë¡¤ë§ ìš”ì•½', {})
            for source in source_summary.keys():
                source_key = source.lower().replace(' ', '_')
                source_summary[source] += crawling_summary.get(source_key, 0)
        
        for source, count in source_summary.items():
            st.write(f"â€¢ {source}: {count}ê°œ ê¸°ì‚¬")
        
        # Enhanced analysis information
        enhanced_count = sum(1 for r in reasons if r.get('ë§í¬ ì¶”ì¶œ ë””ë²„ê·¸'))
        if enhanced_count > 0:
            st.write("**ğŸ”— ê°•í™”ëœ ë§í¬ ë¶„ì„:**")
            st.write(f"â€¢ {enhanced_count}ê°œ ì¢…ëª©ì—ì„œ ì¶”ê°€ ë§í¬ ì½˜í…ì¸  ë¶„ì„ ì™„ë£Œ")
            st.info("ğŸ’¡ ìƒìœ„ ê´€ë ¨ì„± ë§í¬ì—ì„œ ì¶”ì¶œí•œ ì¶”ê°€ ì •ë³´ë¡œ ë” ì •í™•í•œ íˆ¬ì ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤.")
        
        # Summary of issues if any
        error_count = sum(1 for r in reasons if "Error" in str(r.get('ì¶”ì²œ ì‚¬ìœ ', '')))
        if error_count > 0:
            st.warning(f"âš ï¸ {error_count}ê°œ ì¢…ëª©ì—ì„œ ë¶„ì„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
            if not vllm_status:
                st.error("ğŸ”§ ëŒ€ë¶€ë¶„ì˜ ì˜¤ë¥˜ëŠ” vLLM ì„œë²„ ì—°ê²° ë¬¸ì œë¡œ ì¸í•œ ê²ƒì…ë‹ˆë‹¤. ì‹œìŠ¤í…œ ìƒíƒœë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        
    else:  # English
        st.subheader("ğŸ“Š Overall Data Collection Status")
        
        if not vllm_status:
            st.error("âš ï¸ vLLM server connection issues limit AI analysis capabilities. Please check system status to start the vLLM server.")
            st.info("ğŸ’¡ Crawled information is available without vLLM server, but AI-based investment analysis is limited.")
        
        # Overall statistics
        total_stocks = len(reasons)
        total_articles = sum(len(r.get('í¬ë¡¤ë§ëœ ê¸°ì‚¬', [])) for r in reasons)
        total_links = sum(len(r.get('ì°¸ê³  ë§í¬', [])) for r in reasons)
        successful_analyses = sum(1 for r in reasons if r.get('ì¶”ì²œ ì‚¬ìœ ') and "Error" not in str(r.get('ì¶”ì²œ ì‚¬ìœ ', '')))
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("Analyzed Stocks", f"{successful_analyses}/{total_stocks}")
        with col2:
            st.metric("Articles Collected", total_articles)
        with col3:
            st.metric("Reference Links", total_links)
        with col4:
            success_rate = (successful_analyses / total_stocks * 100) if total_stocks > 0 else 0
            st.metric("Success Rate", f"{success_rate:.1f}%")
        
        # Data quality summary
        st.write("**ğŸ“ˆ Data Quality Analysis:**")
        quality_counts = {}
        for r in reasons:
            quality = r.get('í¬ë¡¤ë§ ìš”ì•½', {}).get('data_quality', 'Unknown')
            quality_counts[quality] = quality_counts.get(quality, 0) + 1
        
        for quality, count in quality_counts.items():
            percentage = (count / total_stocks * 100) if total_stocks > 0 else 0
            st.write(f"â€¢ {quality}: {count} stocks ({percentage:.1f}%)")
        
        # Source-wise collection status
        st.write("**ğŸ” Information Source Collection Status:**")
        source_summary = {
            'Google Finance': 0, 'Yahoo Finance': 0, 'MarketWatch': 0, 
            'RSS Feeds': 0, 'DuckDuckGo': 0
        }
        
        for r in reasons:
            crawling_summary = r.get('í¬ë¡¤ë§ ìš”ì•½', {})
            source_mapping = {
                'Google Finance': 'google_finance',
                'Yahoo Finance': 'yahoo_finance', 
                'MarketWatch': 'marketwatch',
                'RSS Feeds': 'rss_feeds',
                'DuckDuckGo': 'duckduckgo'
            }
            for source, key in source_mapping.items():
                source_summary[source] += crawling_summary.get(key, 0)
        
        for source, count in source_summary.items():
            st.write(f"â€¢ {source}: {count} articles")
        
        # Enhanced analysis information
        enhanced_count = sum(1 for r in reasons if r.get('ë§í¬ ì¶”ì¶œ ë””ë²„ê·¸'))
        if enhanced_count > 0:
            st.write("**ğŸ”— Enhanced Link Analysis:**")
            st.write(f"â€¢ {enhanced_count} stocks completed additional link content analysis")
            st.info("ğŸ’¡ Provides more accurate investment analysis with additional information extracted from top relevance links.")
        
        # Summary of issues if any
        error_count = sum(1 for r in reasons if "Error" in str(r.get('ì¶”ì²œ ì‚¬ìœ ', '')))
        if error_count > 0:
            st.warning(f"âš ï¸ {error_count} stocks encountered analysis errors.")
            if not vllm_status:
                st.error("ğŸ”§ Most errors are due to vLLM server connection issues. Please check system status.")
