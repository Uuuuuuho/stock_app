import requests
from config import MODEL_NAME, VLLM_API_URL, MAX_TOKENS, TEMPERATURE

def check_vllm_server():
    """Check if vLLM server is running and accessible."""
    try:
        # Try to ping the server health endpoint
        health_url = VLLM_API_URL.replace('/v1/chat/completions', '/health')
        response = requests.get(health_url, timeout=5)
        if response.status_code == 200:
            return True, "vLLM ì„œë²„ ì—°ê²° ì„±ê³µ"
        else:
            return False, f"vLLM ì„œë²„ ì‘ë‹µ ì˜¤ë¥˜: {response.status_code}"
    except requests.exceptions.ConnectionError:
        return False, f"vLLM ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {VLLM_API_URL}ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
    except requests.exceptions.Timeout:
        return False, "vLLM ì„œë²„ ì—°ê²° ì‹œê°„ ì´ˆê³¼"
    except Exception as e:
        return False, f"vLLM ì„œë²„ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {str(e)}"

def test_vllm_simple():
    """Test vLLM with a simple request."""
    test_payload = {
        "model": MODEL_NAME,
        "messages": [{"role": "user", "content": "Hello, respond with 'Test successful'"}],
        "max_tokens": 10,
        "temperature": 0.1
    }
    
    try:
        response = requests.post(
            VLLM_API_URL, 
            json=test_payload, 
            headers={"Content-Type": "application/json"}, 
            timeout=10
        )
        
        if response.status_code == 200:
            data = response.json()
            content = data.get('choices', [{}])[0].get('message', {}).get('content', '')
            return True, f"í…ŒìŠ¤íŠ¸ ì„±ê³µ: {content}"
        else:
            return False, f"í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {response.status_code} - {response.text}"
            
    except Exception as e:
        return False, f"í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜: {str(e)}"

def run_llm_generic(prompt, language="í•œêµ­ì–´"):
    """Generic LLM request for any prompt."""
    payload = {
        "model": MODEL_NAME,
        "messages": [{"role": "user", "content": prompt}],
        "max_tokens": MAX_TOKENS,
        "temperature": TEMPERATURE
    }
    
    try:
        print(f"ğŸ”„ vLLM ë²”ìš© ìš”ì²­ ì‹œì‘ - Language: {language}")
        print(f"ğŸŒ API URL: {VLLM_API_URL}")
        print(f"ğŸ¤– Model: {MODEL_NAME}")
        
        res = requests.post(VLLM_API_URL, json=payload, headers={"Content-Type":"application/json"}, timeout=30)
        print(f"ğŸ“¡ vLLM Response Status: {res.status_code}")
        
        if res.status_code == 200:
            data = res.json()
            print(f"âœ… vLLM Response received successfully")
            response_content = data['choices'][0]['message']['content'].strip()
            print(f"ğŸ“ Response length: {len(response_content)} characters")
            return response_content, None
        else:
            # Handle model not found error
            if res.status_code == 404 and 'does not exist' in res.text:
                error_msg = (
                    "âŒ vLLM ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. config.pyì˜ MODEL_NAMEì„ ì˜¬ë°”ë¥¸ ëª¨ë¸ëª…ìœ¼ë¡œ ì„¤ì •í•´ì£¼ì„¸ìš”."
                )
            else:
                error_msg = f"vLLM API Error: {res.status_code} - {res.text}"
            print(f"âŒ {error_msg}")
            return error_msg, None
            
    except Exception as e:
        error_msg = f"vLLM API Request Failed: {str(e)}"
        print(f"âŒ {error_msg}")
        return error_msg, None

def run_llm(user_prompt, content, task_name, language="í•œêµ­ì–´"):
    """Simple LLM request for content processing."""
    # Create a simple prompt combining user request and content
    if language == "í•œêµ­ì–´":
        prompt = f"{user_prompt}\n\në‚´ìš©:\n{content}"
    else:
        prompt = f"{user_prompt}\n\nContent:\n{content}"
    
    return run_llm_generic(prompt, language)

def run_llm_stock_analysis(ticker, date, return_pct, articles, language="í•œêµ­ì–´"):
    """Request analysis from vLLM API with enhanced content handling."""
    
    # Check if we have real articles or fallback content
    has_fallback = any("[FALLBACK]" in article for article in articles)
    has_limited_data = len([a for a in articles if not a.startswith("[FALLBACK]")]) < 3
    
    # Format articles for better LLM processing
    formatted_articles = []
    for i, article in enumerate(articles[:10], 1):
        if article and len(article.strip()) > 5:
            formatted_articles.append(f"{i}. {article}")
    
    articles_text = "\n".join(formatted_articles) if formatted_articles else "Limited market information available"
    
    # Language-specific prompts with enhanced context (Korean and English only)
    language_prompts = {
        "í•œêµ­ì–´": f"""
{date}ì— {ticker}ì— íˆ¬ìí–ˆë‹¤ë©´ ì˜¤ëŠ˜ê¹Œì§€ ìˆ˜ìµë¥ ì€ {return_pct:.2f}%ì…ë‹ˆë‹¤.

ìˆ˜ì§‘ëœ ì •ë³´:
{articles_text}

{"âš ï¸ ì£¼ì˜: ì œí•œëœ ë‰´ìŠ¤ ì •ë³´ë¡œ ì¸í•´ ì¼ë°˜ì ì¸ íˆ¬ì ë¶„ì„ì„ í¬í•¨í•©ë‹ˆë‹¤." if has_fallback or has_limited_data else ""}

ì´ ì¢…ëª©ì˜ ìˆ˜ìµë¥  ë°œìƒ ìš”ì¸ì„ í•œêµ­ì–´ë¡œ 3-4ì¤„ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”. 
êµ¬ì²´ì ì¸ ì‹œì¥ ë™í–¥, ê¸°ì—… ì‹¤ì , ë˜ëŠ” ì„¹í„° ì˜í–¥ì„ í¬í•¨í•˜ì—¬ ì„¤ëª…í•´ì£¼ì„¸ìš”.
ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•´ì£¼ì„¸ìš”.
""",
        "English": f"""
If you invested in {ticker} on {date}, the return would be {return_pct:.2f}% until today.

Collected Information:
{articles_text}

{"âš ï¸ Note: Limited news data available, general investment analysis included." if has_fallback or has_limited_data else ""}

Please analyze the factors behind this stock's return in English within 3-4 lines.
Include specific market trends, company performance, or sector impacts in your explanation.
Please respond only in English.
"""
    }
    
    # Get appropriate prompt for selected language
    prompt = language_prompts.get(language, language_prompts["í•œêµ­ì–´"])
    
    return run_llm_generic(prompt, language)

def run_llm_with_enhanced_content(ticker, date, return_pct, articles, links, language="í•œêµ­ì–´"):
    """Enhanced LLM analysis with content from relevant links"""
    from modules.content_extractor import get_enhanced_content_for_ticker
    
    # Get enhanced content from links
    enhanced_content, extraction_debug = get_enhanced_content_for_ticker(ticker, links, max_links=3)
    
    # Check if we have real articles or fallback content
    has_fallback = any("[FALLBACK]" in article for article in articles)
    has_limited_data = len([a for a in articles if not a.startswith("[FALLBACK]")]) < 3
    has_enhanced_content = len(enhanced_content) > 0
    
    # Format articles for better LLM processing
    formatted_articles = []
    for i, article in enumerate(articles[:8], 1):
        if article and len(article.strip()) > 5:
            formatted_articles.append(f"{i}. {article}")
    
    # Add enhanced content from links
    enhanced_text = ""
    if enhanced_content:
        enhanced_text = "\n\nğŸ“° ìƒì„¸ ë¶„ì„ ìë£Œ:\n"
        for i, content_item in enumerate(enhanced_content, 1):
            enhanced_text += f"\n{i}. [ì¶œì²˜: {content_item['url'][:50]}...]\n"
            enhanced_text += f"{content_item['content'][:500]}...\n"
    
    articles_text = "\n".join(formatted_articles) + enhanced_text if formatted_articles else "Limited market information available"
    
    # Enhanced language-specific prompts
    language_prompts = {
        "í•œêµ­ì–´": f"""
{date}ì— {ticker}ì— íˆ¬ìí–ˆë‹¤ë©´ ì˜¤ëŠ˜ê¹Œì§€ ìˆ˜ìµë¥ ì€ {return_pct:.2f}%ì…ë‹ˆë‹¤.

ìˆ˜ì§‘ëœ ì •ë³´:
{articles_text}

{"âš ï¸ ì£¼ì˜: ì œí•œëœ ë‰´ìŠ¤ ì •ë³´ë¡œ ì¸í•´ ì¼ë°˜ì ì¸ íˆ¬ì ë¶„ì„ì„ í¬í•¨í•©ë‹ˆë‹¤." if has_fallback or has_limited_data else ""}
{"âœ¨ ì¶”ê°€: ê´€ë ¨ ë§í¬ì—ì„œ ìƒì„¸ ì •ë³´ë¥¼ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤." if has_enhanced_content else ""}

ì´ ì¢…ëª©ì„ ë§¤ìˆ˜í•´ì•¼ í•˜ëŠ” ì´ìœ ë¥¼ íˆ¬ìì ê´€ì ì—ì„œ í•œêµ­ì–´ë¡œ 4-5ì¤„ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”.
êµ¬ì²´ì ì¸ ì‹œì¥ ë™í–¥, ê¸°ì—… ì‹¤ì , ì„±ì¥ ì „ë§, íˆ¬ì ë§¤ë ¥ë„ë¥¼ í¬í•¨í•˜ì—¬ ì„¤ëª…í•´ì£¼ì„¸ìš”.
ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•´ì£¼ì„¸ìš”.
""",
        "English": f"""
If you invested in {ticker} on {date}, the return would be {return_pct:.2f}% until today.

Collected Information:
{articles_text}

{"âš ï¸ Note: Limited news data available, general investment analysis included." if has_fallback or has_limited_data else ""}
{"âœ¨ Enhancement: Detailed information extracted from relevant links." if has_enhanced_content else ""}

Please analyze why investors should buy this stock from an investment perspective in English within 4-5 lines.
Include specific market trends, company performance, growth prospects, and investment attractiveness.
Please respond only in English.
"""
    }
    
    # Get appropriate prompt for selected language
    prompt = language_prompts.get(language, language_prompts["í•œêµ­ì–´"])
    
    result, _ = run_llm_generic(prompt, language)
    
    # Add enhancement disclaimer
    if has_enhanced_content:
        enhancement_disclaimer_map = {
            "í•œêµ­ì–´": "\n\nâœ¨ ìƒì„¸ ë§í¬ ë¶„ì„ì„ í†µí•œ ê°•í™”ëœ íˆ¬ì ë¶„ì„ì…ë‹ˆë‹¤.",
            "English": "\n\nâœ¨ Enhanced investment analysis through detailed link extraction.",
        }
        enhancement_disclaimer = enhancement_disclaimer_map.get(language, enhancement_disclaimer_map["í•œêµ­ì–´"])
        result += enhancement_disclaimer
    
    # Add disclaimer if using fallback content
    if has_fallback or has_limited_data:
        disclaimer_map = {
            "í•œêµ­ì–´": "\n\nâ€» ì œí•œëœ ë‰´ìŠ¤ ë°ì´í„°ë¡œ ì¸í•œ ì¼ë°˜ì  ë¶„ì„ì„ í¬í•¨í•©ë‹ˆë‹¤.",
            "English": "\n\nâ€» General analysis due to limited news data included.",
        }
        disclaimer = disclaimer_map.get(language, disclaimer_map["í•œêµ­ì–´"])
        result += disclaimer
    
    return result, prompt, extraction_debug
    
    try:
        print(f"ğŸ”„ Enhanced vLLM ìš”ì²­ ì‹œì‘ - Ticker: {ticker}, Language: {language}")
        print(f"ğŸ“Š Articles: {len(articles)}, Enhanced content: {len(enhanced_content)}")
        print(f"ğŸŒ API URL: {VLLM_API_URL}")
        
        res = requests.post(VLLM_API_URL, json=payload, headers={"Content-Type":"application/json"}, timeout=30)
        print(f"ğŸ“¡ vLLM Response Status: {res.status_code}")
        
        if res.status_code == 200:
            data = res.json()
            print(f"âœ… Enhanced vLLM Response received successfully")
            summary = data['choices'][0]['message']['content'].strip()
            print(f"ğŸ“ Summary length: {len(summary)} characters")
            
            # Add enhancement disclaimer
            if has_enhanced_content:
                enhancement_disclaimer_map = {
                    "í•œêµ­ì–´": "\n\nâœ¨ ìƒì„¸ ë§í¬ ë¶„ì„ì„ í†µí•œ ê°•í™”ëœ íˆ¬ì ë¶„ì„ì…ë‹ˆë‹¤.",
                    "English": "\n\nâœ¨ Enhanced investment analysis through detailed link extraction.",
                }
                enhancement_disclaimer = enhancement_disclaimer_map.get(language, enhancement_disclaimer_map["í•œêµ­ì–´"])
                summary += enhancement_disclaimer
            
            # Add disclaimer if using fallback content
            if has_fallback or has_limited_data:
                disclaimer_map = {
                    "í•œêµ­ì–´": "\n\nâ€» ì œí•œëœ ë‰´ìŠ¤ ë°ì´í„°ë¡œ ì¸í•œ ì¼ë°˜ì  ë¶„ì„ì„ í¬í•¨í•©ë‹ˆë‹¤.",
                    "English": "\n\nâ€» General analysis due to limited news data included.",
                }
                disclaimer = disclaimer_map.get(language, disclaimer_map["í•œêµ­ì–´"])
                summary += disclaimer
            
            return summary, prompt, extraction_debug
        else:
            error_msg = f"Enhanced LLM Error {res.status_code}: {res.text}"
            print(f"âŒ {error_msg}")
            return error_msg, prompt, extraction_debug
    except Exception as e:
        error_msg = f"Enhanced LLM request failed: {e}"
        print(f"ğŸ’¥ {error_msg}")
        import traceback
        print(f"ğŸ“‹ Traceback: {traceback.format_exc()}")
        return error_msg, prompt, extraction_debug
